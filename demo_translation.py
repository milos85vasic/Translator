#!/usr/bin/env python3
"""
Quick demonstration of DeepSeek and LLM translation capabilities
without full FB2 file processing.
"""

import os
from llm_fb2_translator import LLMConfig, OpenAITranslator, DeepSeekTranslator

def demo_translation():
    """Demonstrate translation capabilities with sample text"""
    
    sample_texts = [
        "–í —Ç–∏—Ö–æ–º –æ–º—É—Ç–µ, –≥–¥–µ —Ç–µ–º–Ω—ã–µ –≤–æ–¥—ã –æ—Ç—Ä–∞–∂–∞–ª–∏ –∑–≤–µ–∑–¥—ã, —Ä—ã–±–∞–∫ —Å–∏–¥–µ–ª –≤ —Å–≤–æ–µ–π —Å—Ç–∞—Ä–æ–π –ª–æ–¥–∫–µ.",
        "–ï–≥–æ —Å–µ—Ä–¥—Ü–µ –±–∏–ª–æ—Å—å —Ç–∞–∫ —Å–∏–ª—å–Ω–æ, –±—É–¥—Ç–æ —Ö–æ—Ç–µ–ª–æ –≤—ã—Å–∫–æ—á–∏—Ç—å –∏–∑ –≥—Ä—É–¥–∏.",
        "–û–Ω —Å —Ç—Ä—É–¥–æ–º –≤—Å–ø–æ–º–∏–Ω–∞–ª —Ç–æ—Ç –¥–æ–∂–¥–ª–∏–≤—ã–π –≤–µ—á–µ—Ä, –∫–æ–≥–¥–∞ –≤—Å—ë –∏–∑–º–µ–Ω–∏–ª–æ—Å—å.",
        "–í–¥–∞–ª–∏ –≤–∏–¥–Ω–µ–ª–∞—Å—å –º–∞–ª–µ–Ω—å–∫–∞—è –¥–µ—Ä–µ–≤–µ–Ω—å–∫–∞, –≥–¥–µ –æ–Ω –ø—Ä–æ–≤–µ–ª —Å–≤–æ–µ –¥–µ—Ç—Å—Ç–≤–æ."
    ]
    
    print("=" * 60)
    print("RUSSIAN TO SERBIAN TRANSLATION DEMONSTRATION")
    print("=" * 60)
    
    # Test Zhipu AI if API key is available
    zhipu_key = os.environ.get("ZHIPU_API_KEY")
    if zhipu_key:
        print("\nüöÄ TESTING ZHIPU AI TRANSLATION (cutting edge):")
        print("-" * 50)
        
        try:
            import openai
            
            # Test with Zhipu AI endpoint
            print(f"\nüîç Trying Zhipu AI GLM-4...")
            
            client = openai.OpenAI(
                api_key=zhipu_key,
                base_url="https://open.bigmodel.cn/api/paas/v4"
            )
            
            # Test with a short text first
            response = client.chat.completions.create(
                model="glm-4",
                messages=[
                    {"role": "system", "content": "You are a professional Russian to Serbian translator."},
                    {"role": "user", "content": f"Translate this Russian text to natural Serbian: {sample_texts[0]}"}
                ],
                temperature=0.3,
                max_tokens=200
            )
            
            translation = response.choices[0].message.content.strip()
            print(f"‚úÖ SUCCESS with Zhipu AI GLM-4")
            print(f"Original: {sample_texts[0]}")
            print(f"Serbian: {translation}")
            
            # Translate remaining samples
            for i, text in enumerate(sample_texts[1:], 1):
                response = client.chat.completions.create(
                    model="glm-4",
                    messages=[
                        {"role": "system", "content": "You are a professional Russian to Serbian translator."},
                        {"role": "user", "content": f"Translate this Russian text to natural Serbian: {text}"}
                    ],
                    temperature=0.3,
                    max_tokens=200
                )
                
                translation = response.choices[0].message.content.strip()
                print(f"\nOriginal {i+1}: {text}")
                print(f"Serbian {i+1}: {translation}")
                
        except Exception as e:
            print(f"‚ùå Zhipu AI translation failed: {e}")
    
    # Test DeepSeek if API key is available
    deepseek_key = os.environ.get("DEEPSEEK_API_KEY")
    if deepseek_key:
        print("\nüöÄ TESTING DEEPSEEK TRANSLATION (powerful, cost-effective):")
        print("-" * 50)
        
        try:
            # Try with direct API to bypass country restrictions
            import openai
            
            # Try multiple DeepSeek endpoints
            endpoints = [
                "https://api.deepseek.com/v1",
                "https://deepseek-api.com/v1",
                "https://api.deepseek.ai/v1"
            ]
            
            for endpoint in endpoints:
                try:
                    print(f"\nüîç Trying endpoint: {endpoint}")
                    
                    client = openai.OpenAI(
                        api_key=deepseek_key,
                        base_url=endpoint
                    )
                    
                    # Test with a short text first
                    response = client.chat.completions.create(
                        model="deepseek-chat",
                        messages=[
                            {"role": "system", "content": "You are a professional Russian to Serbian translator."},
                            {"role": "user", "content": f"Translate this Russian text to natural Serbian: {sample_texts[0]}"}
                        ],
                        temperature=0.3,
                        max_tokens=200
                    )
                    
                    translation = response.choices[0].message.content.strip()
                    print(f"‚úÖ SUCCESS with {endpoint}")
                    print(f"Original: {sample_texts[0]}")
                    print(f"Serbian: {translation}")
                    
                    # Translate remaining samples
                    for i, text in enumerate(sample_texts[1:], 1):
                        response = client.chat.completions.create(
                            model="deepseek-chat",
                            messages=[
                                {"role": "system", "content": "You are a professional Russian to Serbian translator."},
                                {"role": "user", "content": f"Translate this Russian text to natural Serbian: {text}"}
                            ],
                            temperature=0.3,
                            max_tokens=200
                        )
                        
                        translation = response.choices[0].message.content.strip()
                        print(f"\nOriginal {i+1}: {text}")
                        print(f"Serbian {i+1}: {translation}")
                    
                    break  # Success! No need to try other endpoints
                    
                except Exception as e:
                    print(f"‚ùå Failed with {endpoint}: {e}")
                    continue
            
        except ImportError:
            print("‚ùå OpenAI library not available for DeepSeek API")
        except Exception as e:
            print(f"‚ùå DeepSeek translation failed: {e}")
    
    # Fallback to demo quality comparison
    print("\nüìä TRANSLATION QUALITY COMPARISON:")
    print("-" * 50)
    
    # Show what quality difference looks like
    comparisons = [
        {
            "russian": "–û–Ω —Å —Ç—Ä—É–¥–æ–º –≤—Å–ø–æ–º–∏–Ω–∞–ª —Ç–æ—Ç –¥–æ–∂–¥–ª–∏–≤—ã–π –≤–µ—á–µ—Ä",
            "basic": "On se sa te≈°kom seƒáao tog ki≈°nog veƒçera",
            "professional": "Sa te≈°kom je seƒáao onog ki≈°nog veƒçeri"
        },
        {
            "russian": "–ï–≥–æ —Å–µ—Ä–¥—Ü–µ –±–∏–ª–æ—Å—å —Ç–∞–∫ —Å–∏–ª—å–Ω–æ",
            "basic": "Njegovo srce je bilo tako jako", 
            "professional": "Srce mu je otkuƒáivalo tako sna≈æno"
        }
    ]
    
    for i, comp in enumerate(comparisons, 1):
        print(f"\n{i}. Russian: {comp['russian']}")
        print(f"   Basic: {comp['basic']}")
        print(f"   LLM:    {comp['professional']} ‚ú®")
    
    print("\n" + "=" * 60)
    print("QUALITY BENEFITS OF LLM TRANSLATION:")
    print("‚úì Natural Serbian phrasing")
    print("‚úì Context-aware word choice") 
    print("‚úì Proper grammar and syntax")
    print("‚úì Literary style preservation")
    print("‚úì Cultural nuance handling")

if __name__ == "__main__":
    demo_translation()