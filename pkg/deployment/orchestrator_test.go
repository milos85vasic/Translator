package deployment

import (
	"context"
	"fmt"
	"os"
	"strings"
	"testing"
	"time"

	"digital.vasic.translator/internal/config"
	"digital.vasic.translator/pkg/events"
	"github.com/stretchr/testify/assert"
)

func TestDeploymentOrchestrator_DeployDistributedSystem(t *testing.T) {
	// Setup
	cfg := &config.Config{}
	eventBus := events.NewEventBus()
	orchestrator := NewDeploymentOrchestrator(cfg, eventBus)
	defer orchestrator.Close()

	// Create a simple deployment plan
	plan := &DeploymentPlan{
		Main: &DeploymentConfig{
			Host:          "localhost",
			User:          "test",
			SSHKeyPath:    "/dev/null", // Won't actually connect
			DockerImage:   "test:latest",
			ContainerName: "test-main",
			Ports: []PortMapping{
				{HostPort: 8443, ContainerPort: 8443, Protocol: "tcp"},
			},
			Environment:   map[string]string{"TEST": "true"},
			Networks:      []string{"test-network"},
			RestartPolicy: "unless-stopped",
		},
		Workers: []*DeploymentConfig{}, // Empty for this test
	}

	// Test deployment (will fail due to no actual SSH/docker, but tests the logic)
	ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
	defer cancel()

	err := orchestrator.DeployDistributedSystem(ctx, plan)

	// We expect this to fail because we don't have actual SSH/docker setup
	// But it should fail gracefully, not panic
	if err == nil {
		t.Error("Expected deployment to fail with test setup, but it succeeded")
	}

	// Check that the error is related to SSH connection, not a panic
	t.Logf("Deployment failed as expected: %v", err)
}

func TestDeploymentOrchestrator_FindAvailablePort(t *testing.T) {
	cfg := &config.Config{}
	eventBus := events.NewEventBus()
	orchestrator := NewDeploymentOrchestrator(cfg, eventBus)
	defer orchestrator.Close()

	// Test finding an available port
	port, err := orchestrator.findAvailablePort("localhost", 8443)
	if err != nil {
		t.Fatalf("Failed to find available port: %v", err)
	}

	if port < 8443 {
		t.Errorf("Expected port >= 8443, got %d", port)
	}

	t.Logf("Found available port: %d", port)
}

func TestDeploymentOrchestrator_ValidateDeploymentPlan(t *testing.T) {
	cfg := &config.Config{}
	eventBus := events.NewEventBus()
	orchestrator := NewDeploymentOrchestrator(cfg, eventBus)
	defer orchestrator.Close()

	tests := []struct {
		name    string
		plan    *DeploymentPlan
		wantErr bool
	}{
		{
			name: "valid plan",
			plan: &DeploymentPlan{
				Main: &DeploymentConfig{
					Host:          "localhost",
					User:          "test",
					DockerImage:   "test:latest",
					ContainerName: "test-main",
					Ports:         []PortMapping{{HostPort: 8443, ContainerPort: 8443}},
				},
				Workers: []*DeploymentConfig{
					{
						Host:          "localhost",
						User:          "test",
						DockerImage:   "test:latest",
						ContainerName: "test-worker-1",
						Ports:         []PortMapping{{HostPort: 8444, ContainerPort: 8443}},
					},
				},
			},
			wantErr: false,
		},
		{
			name: "missing main config",
			plan: &DeploymentPlan{
				Main:    nil,
				Workers: []*DeploymentConfig{},
			},
			wantErr: true,
		},
		{
			name: "invalid main config - no host",
			plan: &DeploymentPlan{
				Main: &DeploymentConfig{
					User:          "test",
					DockerImage:   "test:latest",
					ContainerName: "test-main",
				},
				Workers: []*DeploymentConfig{},
			},
			wantErr: true,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			err := orchestrator.validateDeploymentPlan(tt.plan)
			if (err != nil) != tt.wantErr {
				t.Errorf("validateDeploymentPlan() error = %v, wantErr %v", err, tt.wantErr)
			}
		})
	}
}

func TestDeploymentOrchestrator_GetDeployedInstances(t *testing.T) {
	cfg := &config.Config{}
	eventBus := events.NewEventBus()
	orchestrator := NewDeploymentOrchestrator(cfg, eventBus)
	defer orchestrator.Close()

	// Initially should be empty
	instances := orchestrator.GetDeployedInstances()
	if len(instances) != 0 {
		t.Errorf("Expected 0 instances initially, got %d", len(instances))
	}

	// Add a mock instance
	mockInstance := &DeployedInstance{
		ID:          "test-instance",
		Host:        "localhost",
		Port:        8443,
		ContainerID: "mock-container-id",
		Status:      "healthy",
		LastSeen:    time.Now(),
	}

	orchestrator.mu.Lock()
	orchestrator.deployed["test-instance"] = mockInstance
	orchestrator.mu.Unlock()

	// Now should have one instance
	instances = orchestrator.GetDeployedInstances()
	if len(instances) != 1 {
		t.Errorf("Expected 1 instance, got %d", len(instances))
	}

	if instance, exists := instances["test-instance"]; !exists {
		t.Error("Expected test-instance to exist")
	} else {
		if instance.ID != "test-instance" {
			t.Errorf("Expected instance ID 'test-instance', got '%s'", instance.ID)
		}
	}
}

// Additional comprehensive tests to enhance coverage

func TestDockerOrchestrator_GenerateComposeFile(t *testing.T) {
	cfg := &config.Config{
		Distributed: config.DistributedConfig{
			Enabled: true,
			Workers: map[string]config.WorkerConfig{
				"worker1": {
					Name:        "worker1",
					Host:        "worker1.example.com", 
					Port:        22, 
					User:        "deploy",
					MaxCapacity: 10,
					Enabled:     true,
				},
			},
		},
	}
	eventBus := events.NewEventBus()
	orchestrator := NewDeploymentOrchestrator(cfg, eventBus)
	defer orchestrator.Close()

	// Test with multiple workers
	plan := &DeploymentPlan{
		Main: &DeploymentConfig{
			Host:          "localhost",
			User:          "test",
			DockerImage:   "translator:latest",
			ContainerName: "translator-main",
			Ports: []PortMapping{
				{HostPort: 8443, ContainerPort: 8443, Protocol: "tcp"},
				{HostPort: 8080, ContainerPort: 8080, Protocol: "tcp"},
			},
			Environment: map[string]string{
				"ENV": "production",
				"LOG_LEVEL": "info",
			},
			Volumes: []VolumeMapping{
				{HostPath: "/data", ContainerPath: "/app/data", ReadOnly: false},
				{HostPath: "/config", ContainerPath: "/app/config", ReadOnly: true},
			},
			Networks:      []string{"translator-network"},
			RestartPolicy: "unless-stopped",
		},
		Workers: []*DeploymentConfig{
			{
				Host:          "worker1.example.com",
				User:          "deploy",
				DockerImage:   "translator:latest",
				ContainerName: "translator-worker-1",
				Ports:         []PortMapping{{HostPort: 8444, ContainerPort: 8443}},
				Environment:   map[string]string{"WORKER_ID": "1"},
				Networks:      []string{"translator-network"},
				RestartPolicy: "unless-stopped",
			},
			{
				Host:          "worker2.example.com",
				User:          "deploy",
				DockerImage:   "translator:latest",
				ContainerName: "translator-worker-2",
				Ports:         []PortMapping{{HostPort: 8445, ContainerPort: 8443}},
				Environment:   map[string]string{"WORKER_ID": "2"},
				Networks:      []string{"translator-network"},
				RestartPolicy: "unless-stopped",
			},
		},
	}

	// Note: Since GenerateComposeFile may not exist in actual DeploymentOrchestrator,
	// we'll test the concept by calling docker orchestrator methods directly
	do := NewDockerOrchestrator(cfg, eventBus)
	// No Close method available on DockerOrchestrator, so we skip it for now

	composePath, err := do.GenerateComposeFile(plan)
	if err != nil {
		t.Fatalf("Failed to generate compose file: %v", err)
	}

	if composePath == "" {
		t.Error("Expected non-empty compose path")
	}

	// Verify file exists and has content
	if _, err := os.Stat(composePath); os.IsNotExist(err) {
		t.Errorf("Compose file does not exist at %s", composePath)
	}

	t.Logf("Generated compose file at: %s", composePath)
}

func TestDeploymentOrchestrator_ConfigValidation(t *testing.T) {
	tests := []struct {
		name        string
		config      *DeploymentConfig
		expectError bool
	}{
		{
			name: "Valid configuration",
			config: &DeploymentConfig{
				Host:          "valid.example.com",
				User:          "deploy",
				DockerImage:   "translator:latest",
				ContainerName: "valid-container",
				Ports:         []PortMapping{{HostPort: 8443, ContainerPort: 8443}},
			},
			expectError: false,
		},
		{
			name: "Missing host",
			config: &DeploymentConfig{
				User:          "deploy",
				DockerImage:   "translator:latest",
				ContainerName: "valid-container",
			},
			expectError: true,
		},
		{
			name: "Invalid port mapping",
			config: &DeploymentConfig{
				Host:          "valid.example.com",
				User:          "deploy",
				DockerImage:   "translator:latest",
				ContainerName: "valid-container",
				Ports:         []PortMapping{{HostPort: 80, ContainerPort: 8443}}, // privileged port
			},
			expectError: true,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			cfg := &config.Config{}
			eventBus := events.NewEventBus()
			orchestrator := NewDeploymentOrchestrator(cfg, eventBus)
			defer orchestrator.Close()

			err := orchestrator.ValidateConfig(tt.config)
			
			if tt.expectError {
				assert.Error(t, err, "Expected validation error for config: %s", tt.name)
			} else {
				assert.NoError(t, err, "Expected no validation error for config: %s", tt.name)
			}
		})
	}
}

// Mock methods to be added to DeploymentOrchestrator for testing
func (do *DeploymentOrchestrator) ValidateConfig(config *DeploymentConfig) error {
	// Basic validation logic for testing
	if config.Host == "" {
		return fmt.Errorf("host is required")
	}
	if config.User == "" {
		return fmt.Errorf("user is required")
	}
	if config.DockerImage == "" {
		return fmt.Errorf("docker image is required")
	}
	if strings.Contains(config.DockerImage, " ") {
		return fmt.Errorf("invalid docker image name")
	}
	
	// Check for privileged ports
	for _, port := range config.Ports {
		if port.HostPort < 1024 && port.HostPort != 80 && port.HostPort != 443 {
			return fmt.Errorf("privileged port %d not allowed", port.HostPort)
		}
	}
	
	return nil
}
